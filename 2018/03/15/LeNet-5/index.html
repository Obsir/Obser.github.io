<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-big.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-small.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo_custom.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="python,machine learning,tensorflow,经典网络," />










<meta name="description" content="以下部分内容转载自LeNet论文的翻译与CNN三大核心思想的解读，卷积神经网络 LeNet-5各层参数详解 相关资料下面列出的论文都是CNN必读的论文，论文的顺序基本上就是CNN结构演化的历史。  LeNet:《Gradient-Based Learning Applied to Document Recognition》 CNN的开山之作，也是手写体识别经典论文。 AlexNet:《 Image">
<meta name="keywords" content="python,machine learning,tensorflow,经典网络">
<meta property="og:type" content="article">
<meta property="og:title" content="经典网络LeNet-5论文解读以及Tensorflow实现">
<meta property="og:url" content="http://yoursite.com/2018/03/15/LeNet-5/index.html">
<meta property="og:site_name" content="Observer">
<meta property="og:description" content="以下部分内容转载自LeNet论文的翻译与CNN三大核心思想的解读，卷积神经网络 LeNet-5各层参数详解 相关资料下面列出的论文都是CNN必读的论文，论文的顺序基本上就是CNN结构演化的历史。  LeNet:《Gradient-Based Learning Applied to Document Recognition》 CNN的开山之作，也是手写体识别经典论文。 AlexNet:《 Image">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_1.jpg">
<meta property="og:image" content="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_2.jpg">
<meta property="og:image" content="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_3.jpg">
<meta property="og:image" content="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_4.png">
<meta property="og:image" content="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_5.jpg">
<meta property="og:image" content="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_6.jpg">
<meta property="og:image" content="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_7.jpg">
<meta property="og:image" content="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_8.jpg">
<meta property="og:image" content="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_9.jpg">
<meta property="og:image" content="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_10.jpg">
<meta property="og:image" content="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_11.jpg">
<meta property="og:image" content="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_12.png">
<meta property="og:image" content="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/cost.png">
<meta property="og:updated_time" content="2020-09-21T12:28:28.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="经典网络LeNet-5论文解读以及Tensorflow实现">
<meta name="twitter:description" content="以下部分内容转载自LeNet论文的翻译与CNN三大核心思想的解读，卷积神经网络 LeNet-5各层参数详解 相关资料下面列出的论文都是CNN必读的论文，论文的顺序基本上就是CNN结构演化的历史。  LeNet:《Gradient-Based Learning Applied to Document Recognition》 CNN的开山之作，也是手写体识别经典论文。 AlexNet:《 Image">
<meta name="twitter:image" content="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_1.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: 'A3MCEEQSRG',
      apiKey: '',
      indexName: 'test_obser',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/03/15/LeNet-5/"/>





  <title>经典网络LeNet-5论文解读以及Tensorflow实现 | Observer</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Observer</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Watch And Learn</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>

<a href="https://github.com/obsir" class="github-corner" aria-label="View source on Github"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#fff; color:#151513; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/15/LeNet-5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Obser">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://obser.oss-cn-beijing.aliyuncs.com/img/avatar_0.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Observer">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">经典网络LeNet-5论文解读以及Tensorflow实现</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-15T20:00:44+08:00">
                2018-03-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2018/03/15/LeNet-5/" class="leancloud_visitors" data-flag-title="经典网络LeNet-5论文解读以及Tensorflow实现">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <script src="/assets/js/APlayer.min.js"> </script><p><strong>以下部分内容转载自</strong><a href="blog.csdn.net/qianqing13579/article/details/71076261">LeNet论文的翻译与CNN三大核心思想的解读</a>，<a href="https://www.jianshu.com/p/ce609f9b5910" target="_blank" rel="noopener">卷积神经网络 LeNet-5各层参数详解</a></p>
<h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><p>下面列出的论文都是CNN必读的论文，论文的顺序基本上就是CNN结构演化的历史。</p>
<ul>
<li><strong>LeNet:《Gradient-Based Learning Applied to Document Recognition》</strong> CNN的开山之作，也是手写体识别经典论文。</li>
<li><strong>AlexNet:《 ImageNet Classification with Deep Convolutional Neural Networks 》</strong> ILSVRC-2012 大赛冠军，促进CNN的扛鼎之作，AlexNet是CNN发展史上的一个历史性转折，不能不读。</li>
<li><strong>Inception V1和V3:《Going Deeper with Convolutions》,《Rethinking the Inception Architecture for Computer Vision》</strong>,2014年ImageNet大赛冠军,Inception结构的设计很巧妙</li>
<li><strong>VGGNet:《Very Deep Convolutional Networks for Large-Scale Image Recognition》</strong>,虽然不是那年ImageNet大赛的冠军(那年的冠军是GoogLeNet),但是VGGNet对后面的ResNet，Inception产生了重要的影响</li>
<li><strong>DeepID2+:《Deeply learned face representations are sparse, selective, and robust》</strong>为什么要推荐这篇论文呢？人脸识别领域，DeepID大名如雷贯耳，与DeepID,DeepID2不同的是，这篇论文并不是单纯讲人脸识别，论文深入分析了CNN的内部结构，试图从理论上解释CNN强大的特征提取能和分类识别能力，这是学者第一次试图去探索CNN的本质属性，看完这篇论文，相信对CNN会有更深入的了解。</li>
<li><strong>ResNet:《Deep Residual Learning for Image Recognition》</strong>，直接将top5错误率降到了3.57%（GoogLeNet 是6.66%），超越了人眼，文中最大的亮点就是残差块结构的设计。</li>
</ul>
<a id="more"></a>
<p>以下的博客对于学习CNN可以提供很大的帮助，感谢作者的分享</p>
<ul>
<li><a href="http://www.cnblogs.com/subconscious/p/5058741.html" target="_blank" rel="noopener">神经网络浅讲：从神经元到深度学习</a>，较好的阐述了神经网络的历史</li>
<li><a href="http://www.hankcs.com/ml/back-propagation-neural-network.html" target="_blank" rel="noopener">反向传播神经网络极简入门</a>，反向传播资料</li>
<li><a href="http://blog.csdn.net/zouxy09/article/details/8775360" target="_blank" rel="noopener">Deep Learning（深度学习）学习笔记整理系列之（一）</a>网友整理的深度学习的笔记，值得一读。</li>
</ul>
<p>还有一些资料，也非常值得学习</p>
<ul>
<li><strong>CS231n</strong>，是斯坦福的一门课程，这里有篇文章整理了相关资源 <a href="https://zhuanlan.zhihu.com/p/21930884" target="_blank" rel="noopener">贺完结！CS231n官方笔记授权翻译总集篇发布</a></li>
<li><strong>《Deep Learning》</strong> Yoshua Bengio，Ian Goodfellow，Aaron Courville写的一本书</li>
<li><strong>《On the Origin of Deep Learning》</strong>，这篇论文对深度学习的发展历史做了一个综述，与CNN相关的第5章：Convolutional Neural Networks and Vision Problems，其中提到了CNN目前遇到的挑战以及机遇。</li>
</ul>
<p>这里附上一张CNN结构演化历史的图，希望帮助大家更好的了解CNN的发展</p>
<p><img src="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_1.jpg" alt="aliyun-obser"></p>
<p>上面提到的论文和书籍都是可以在网上下载到的，<a href="http://download.csdn.net/detail/qianqing13579/9830704" target="_blank" rel="noopener">点击下载</a>。</p>
<h2 id="LeNet论文翻译"><a href="#LeNet论文翻译" class="headerlink" title="LeNet论文翻译"></a>LeNet论文翻译</h2><p>由于LeNet这篇论文篇幅较长，这里只翻译了对理解CNN很关键的第二章的A和B，这部分阐述了CNN的三个重要思想。下面就是第二部分的翻译。</p>
<h3 id="2-用于字符识别的卷积神经网络"><a href="#2-用于字符识别的卷积神经网络" class="headerlink" title="2 用于字符识别的卷积神经网络"></a>2 用于字符识别的卷积神经网络</h3><p>使用梯度下降法的多层网络可以从大量的数据中学习复杂的，高纬，非线性的映射，这使得他们成为图像识别任务的首选。在传统的模式识别的模型中，手工设计的特征提取器从图像中提取相关特征清除不相关的信息。分类器可以将这些特征进行分类。全连接的多层网络可以作为分类器。一个更有意思的模式就是尽量依赖特征提取器本身进行学习。对于字符识别，可以将图像作为行向量作为输入输入到网络中。虽然这些任务(比如字符识别)可以使用传统的前向全连接网络完成。但是还存在一些问题。</p>
<p>首先，图像是非常大的，由很多像素组成。具有100个隐藏单元的全连接网络包含成千上万的权重，这么多参数提高了系统的消耗和内存占用，因此需要更大的训练集。但是没有结构的网络的主要缺点是，多于图像或者音频这些应用来说，不具备平移，形变扭曲的不变性。在输入到固定大小输入的网络钱，字符图像的大小必须归一化，并且放在输入的中间，不幸的是，没有哪种预处理能够达到如此完美：由于手写体以字符为归一化单位，会导致每个字符的大小，倾斜，位置存在变化，再加上书写风格的差异，将会导致特征位置的变化，原则上，足够大小的全连接网络可以对这些变化鲁棒，但是，要达到这种目的需要更多的在输入图像不同位置的神经元，这样可以检测到不同的特征，不论他们出现在图像的什么位置。学习这些权值参数需要大量的训练样本去覆盖可能的样本空间，在下面描述的卷积神经网络中，位移不变性(shift invariance)可以通过权值共享实现。</p>
<p>第2点，全连接的网络的另一个缺点就是完全忽略了输入的拓扑结构。在不影响训练的结果的情况下，输入图像可以是任意的顺序。然而，图像具有很强的二维局部结构：空间相邻的像素具有高度相关性。局部相关性对于提取局部特征来说具有巨大优势，因为相邻像素的权值可以分成几类。CNN通过将隐藏结点的感受野限制在局部来提取特征。</p>
<h3 id="A-卷积网络"><a href="#A-卷积网络" class="headerlink" title="A 卷积网络"></a>A 卷积网络</h3><p>CNN通过局部感受野(local receptive fields)，权值共享(shared weights)，下采样(sub-sampling)实现位移，缩放，和形变的不变性(shift,scale,distortion invariance)。一个典型的用于字符识别的网络结构如图2所示，该网络结构称为LeNet-5。输入层输入大小归一化并且字符位于中间的字符图像。每一层的每个神经元(each unit)接受上一层中一组局部领域的神经元的输入(就是局部感受野)。将多个神经元连接为局部感受野的思想可以追溯到60年代的感知机，与Hubel and Wiesel’s在猫的视觉系统中发现的局部感受和方向选择的神经元几乎是同步的（神经网络和神经科学关系密切）。局部感受野在视觉学习神经模型中使用很多次了，使用局部感受野，神经元能够提取边缘，角点等视觉特征，这些特征在下一层中进行结合形成更高层的特征，之前提到，形变和位移会导致显著特征位置的变化，此外图像局部的特征检测器也可以用于整个图像，基于这个特性，我们可以将局部感受野位于图像不同位置的一组神经元设置为相同的权值(这就是权值共享)。每一层中所有的神经元形成一个平面，这个平面中所有神经元共享权值。神经元(unit)的所有输出构成特征图，特征图中所有单元在图像的不同位置执行相同的操作，这样他们可以在输入图像的不同位置检测到同样的特征，一个完整的卷积层由多个特征图组成(使用不同的权值向量)，这样每个位置可以提取多种特征。一个具体的示例就是图2 LeNet-5中的第一层，第一层隐藏层中的所有单元形成6个平面，每个是一个特征图。一个特征图中的一个单元对应有25个输入，这25个输入连接到输入层的5x5区域，这个区域就是局部感受野。每个单元有25个输入，因此有25个可训练的参数加上一个偏置。由于特征图中相邻单元以前一层中连续的单元为中心，所以相邻单元的局部感受野是重叠的。比如，LeNet-5中，水平方向连续的单元的感受野存在5行4列的重叠，之前提到过，一个特征图中所有单元共享25个权值和一个偏置，所以他们在输入图像的不同位置检测相同的特征，每一层的其他特征图使用不同的一组权值和偏置，提取不同类型的局部特征。LeNet中，每个输入位置会提取6个不同的特征。特征图的一种实现方式就是使用一个带有感受野的单元，扫面整个图像，并且将每个对应的位置的状态保持在特征图中，这种操作等价于卷积，后面加入一个偏置和一个函数，因此，取名为卷积网络，卷积核就是连接的权重。卷积层的核就是特征图中所有单元使用的一组连接权重。卷积层的一个重要特性是如果输入图像发生了位移，特征图会发生相应的位移，否则特征图保持不变。这个特性是CNN对位移和形变保持鲁棒的基础。</p>
<p>一旦计算出feature map,那么精确的位置就变得不重要了，相对于其他特征的大概位置是才是相关的。比如，我们知道左上方区域有一个水平线段的一个端点，右上方有一个角，下方垂直线段有一个端点，我们就知道这个数字是7。这些特征的精确位置不仅对识别没有帮助，反而不利于识别，因为对于不同的手写体字符，位置会经常变动。在特征图中降低特征位置的精度的方式是降低特征图的空间分辨率，这个可以通过下采样层达到，下采样层通过求局部平均降低特征图的分辨率，并且降低了输出对平移和形变的敏感度。&gt;LeNet-5中的第二个隐藏层就是下采样层。这个层包含了6个特征图，与前一层的6个特征图对应。每个神经元的感受野是2x2,每个神经元计算四个输入的平均，然后乘以一个系数，最后加上一个偏执，最后将值传递给一个sigmoid函数。相邻的神经元的感受野没有重叠。因此，下采样层的特征图的行和列是前一层特征图的一半。系数和偏置影响了sigmoid函数的效果。如果系数比较小，下采样层相当于对输入做了模糊操作。如果系数较大，根据偏置的值下采样层可以看成是“或”或者“与”操作。卷积层和下采样层是交替出现的，这种形式形成一个金字塔：每一层，特征图的分辨率逐渐减低，而特征图的数量逐渐增加。LeNet-5中第三个隐藏层(C3层)的每个神经元的输入可以来自前一层(S2)的多个特征图。卷积和下采样的结合的灵感来源于Hubel and Wiesel’s”简单”和”复杂”细胞的概念,虽然那个时候没有像反向传播的全局监督学习过程。下采样以及多个特征结合可以大大提高网络对几何变换的不变性。</p>
<p>由于所有的权值都是通过反向传播学习的，卷积网络可以看成是一个特征提取器。权值共享技术对降低参数的数量有重要的影响，同时权值共享技术减小了测试误差和训练误差之间的差距。LeNet-5包含了340908个连接，但是由于权值共享只包含了60000个可训练的参数。</p>
<p>卷积神经网络以及被应用在多个领域，包括手写体识别，打印字符识别，在线手写体提识别，以及人脸识别。在单个时间维度上权值共享的卷积神经网络被称为延时神经网络(TDNNs),TDNNs已经被用在场景识别(没有下采样)[40],语音识别（没有下采样），独立的手写体字符识别[44]以及手势验证[45]。</p>
<h3 id="B-LeNet-5"><a href="#B-LeNet-5" class="headerlink" title="B LeNet-5"></a>B LeNet-5</h3><p><img src="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_2.jpg" alt="aliyun-obser"></p>
<p>LeNet-5共有7层，不包含输入，每层都包含可训练参数（连接权重）。输入图像为<code>32*32</code>大小。这要比Mnist数据库（一个公认的手写数据库）中最大的字母还大（<code>28*28</code>）。这样做的原因是希望潜在的明显特征如笔画端点或角点能够出现在最高层特征监测器感受野的中心。在LeNet-5中，最后一层卷积层的感受野的中心在32x32的输入图像中形成了一个20x20的区域，输入像素值被归一化了，这样背景(白色)对应-0.1，前景(黑色)对应1.175.这使得输入的均值约等于0，方差约等于1，这样能够加速学习[46]。</p>
<p>下文中，卷积层标识为Cx,下采样层标识为Sx,全连接层标识为Fx,x标识层的索引。</p>
<p>C1层是一个卷积层，由6个特征图Feature Map构成。特征图中每个神经元与输入中<code>5*5</code>的邻域相连。特征图的大小为<code>28*28</code>，这样能防止输入的连接掉到边界之外。C1有156个可训练参数（每个滤波器<code>5*5=25</code>个unit参数和一个bias参数，一共6个滤波器，共<code>(5*5+1)*6=156</code>个参数），共122,304个连接（<code>26*28*28*6</code>，每个神经元对应26个连接，每个feature map有<code>28*28</code>个unit, 一共有6个feature map）。</p>
<p>S2层是一个下采样层，有6个<code>14*14</code>的特征图。特征图中的每个单元与C1中相对应特征图的<code>2*2</code>邻域相连接。S2层每个单元的4个输入相加，乘以一个可训练参数，再加上一个可训练偏置。结果通过sigmoid函数计算。可训练系数和偏置控制着sigmoid函数的非线性程度。如果系数比较小，那么运算近似于线性运算，下采样相当于模糊图像。如果系数比较大，根据偏置的大小下采样可以被看成是有噪声的“或”运算或者有噪声的“与”运算。每个单元的<code>2*2</code>感受野并不重叠，因此S2中每个特征图的行列分别是C1中特征图的一半。S2层有12个可训练参数(每个feature map有一个系数和偏置)和5880个连接。</p>
<p>C3是一个有16个特征图的卷积层。C3层的卷积核大小为<code>5*5</code>，每个特征图中的每个单元与S2中的多个特征图相连，表1显示了C3中每个特征图与S2中哪些特征图相连。<br>那为什么不把S2中的每个特征图连接到每个C3的特征图呢？原因有2点。<br>第一，不完全的连接机制将连接的数量保持在合理的范围内。<br>第二，也是更加重要的，其破坏了网络的对称性。不完全连接能够保证C3中不同特征图提取不同的特征（希望是互补的），因为他们的输入不同。<br>表1中展示了一个合理的连接方式：C3的前6个特征图以S2中3个相邻的特征图为输入。接下来6个特征图以S2中4个相邻特征图为输入，下面的3个特征图以不相邻的4个特征图为输入。最后一个特征图以S2中所有特征图为输入。这样C3层有1516个可训练参数(<code>(25*3+1)*6+(25*4+1)*9+(25*6+1)</code>)和151600个连接。</p>
<p><img src="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_3.jpg" alt="aliyun-obser"></p>
<p>(表1中第1列表示C3的第0个特征图，与S2中的第0,1,2个特征图连接）</p>
<p>S4层是一个下采样层，由16个<code>5*5</code>大小的特征图构成。特征图中的每个单元与C3中相应特征图的<code>2*2</code>邻域相连接，跟C1和S2之间的连接一样。S4层有32个可训练参数（每个特征图1个系数和一个偏置）和2000个连接(<code>5*5*5*16</code>,对于S4的每个unit,对应感受野4个参数，加上一个偏置)。</p>
<p>C5层是一个卷积层，有120个特征图。每个单元与S4层的全部16个特征图的<code>5*5</code>领域相连。由于S4层特征图的大小也为<code>5*5</code>（同滤波器一样），故C5特征图的大小为<code>1*1</code>：这构成了S4和C5之间的全连接。之所以仍将C5标示为卷积层而非全连接层，是因为如果LeNet-5的输入变大，而其他的保持不变，那么此时特征图的维数就会比<code>1*1</code>大。C5层有48120个可训练连接(<code>(5*5*16+1)*120</code>)。</p>
<p>F6层有84个单元（之所以选这个数字的原因来自于输出层的设计，下面会有说明），与C5层全相连。有10164个可训练参数。</p>
<p>如同经典神经网络，F6层计算输入向量和权重向量之间的点积，再加上一个偏置。神经元i的加权和表示为$a_i$,然后将其传递给sigmoid函数产生单元i的一个状态，表示为$x_i$, </p>
<script type="math/tex; mode=display">x_i = f(a_i)</script><p>Sigmoid函数是一个双曲线正切函数： </p>
<script type="math/tex; mode=display">f(a)=Atanh(Sa)</script><p>A表示函数的振幅，S决定了斜率，这个函数是一个奇函数，水平渐近线为+A，-A。常量A通常取1.7159。选择该函数的原因见附录A。</p>
<p>最后，输出层(其实就是softmax loss)由欧式径向基函数（Euclidean Radial Basis Function,RBF）单元组成，每类一个单元，每个单元有84个输入，每个RBF单元$y_i$的输出按照如下方式计算： </p>
<script type="math/tex; mode=display">y_i = \sum(x_j - w_ij)^2</script><p>换句话说，每个输出RBF单元计算输入向量和参数向量之间的欧式距离。输入离参数向量越远，RBF输出的越大。一个RBF输出可以被理解为衡量输入模式和与RBF相关联类的一个模型的匹配程度的惩罚项。用概率术语来说，RBF输出可以被理解为F6层配置空间的高斯分布的负的log似然(log-likelihood)。给定一个输入模式，损失函数应能使得F6的配置与RBF参数向量（即模式的期望分类）足够接近。这些单元的参数是人工选取并保持固定的（至少初始时候如此）。这些参数向量的成分被设为-1或1。虽然这些参数可以以-1和1等概率的方式任选，或者构成一个纠错码，但是被设计成一个相应字符类的7*12大小（即84）的格式化图片。这种表示对识别单独的数字不是很有用，但是对识别可打印ASCII集中的字符串很有用。基本原理就是字符是相似的，容易混淆，比如大小的O,小写的o和数字0或者小写的l与数字1，方括号和大写的I，会有相似的输出编码。如果一个系统与一个能够纠正此混淆的语言处理器相结合，这个就非常有用了。由于容易混淆的类别的编码是相似的，有歧义的字符的RBF输出是相似的，这个语言处理器就能够选择出合适的解释。图3给出了所有ASCII字符集的输出编码。</p>
<p><img src="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_4.png" alt="aliyun-obser"></p>
<p>使用这种分布编码而非更常用的“1 of N”编码(又叫位置编码或者细胞编码)用于产生输出的另一个原因是，当类别比较大的时候，非分布编码的效果比较差。原因是大多数时间非分布编码的输出必须是关闭状态。这使得用sigmoid单元很难实现。另一个原因是分类器不仅用于识别字母，也用于拒绝非字母。使用分布编码的RBF更适合该目的，因为与sigmoid不同，他们在输入空间的较好得限制区域内兴奋，而非典型模式更容易落到外边。</p>
<p>RBF参数向量起着F6层目标向量的角色。需要指出这些向量的成分是+1或-1，这正好在F6 sigmoid的范围内，因此可以防止sigmoid函数饱和。实际上，+1和-1是sigmoid函数的最大曲率的点。这使得F6单元运行在最大非线性范围内。必须避免sigmoid函数的饱和，因为这将会导致损失函数较慢的收敛和病态问题。</p>
<h3 id="LeNet论文解读"><a href="#LeNet论文解读" class="headerlink" title="LeNet论文解读"></a>LeNet论文解读</h3><h3 id="神经元模型"><a href="#神经元模型" class="headerlink" title="神经元模型"></a>神经元模型</h3><p><img src="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_5.jpg" alt="aliyun-obser"></p>
<p>神经元模型是一个包含输入，输出的计算模型。</p>
<font color="red">一个神经元对应一组权值(CNN中的卷积核+偏置)，执行一次计算$$ y=f(\sumω_ix_i+b) $$(CNN中的卷积计算)，产生一个输出(CNN中特征图的一个像素)。</font>

<h3 id="从传统神经网络到CNN"><a href="#从传统神经网络到CNN" class="headerlink" title="从传统神经网络到CNN"></a>从传统神经网络到CNN</h3><p>第二章一开始，作者讨论了传统的全连接神经网络网络的缺点。</p>
<p>传统神经网络中，假设有如下全连接网络</p>
<p><img src="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_6.jpg" alt="aliyun-obser"></p>
<p>如果我们有1000x1000像素的图像，有1百万个隐层神经元，那么他们全连接的话（每个隐层神经元都连接图像的每一个像素点），就有1000x1000x1000000个连接，也就是$10^12$个权值参数，带来的缺点：</p>
<ol>
<li>权值参数多，系统开销大。</li>
<li><font color="red">全连接网络每个神经元感受到的都是整幅图像，对平移，形变不具有不变性。</font>只要对同一幅图像加入一些扰动，输出就会不同。</li>
<li><font color="red">全连接网络完全忽略了图像的局部结构</font>，在不改变神经元的输出的前提下，输入数据可以是任意的顺序。</li>
</ol>
<p><img src="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_7.jpg" alt="aliyun-obser"></p>
<p>作者借鉴了视觉神经中局部感受神经元的思想，提出了局部感受野的概念，就是每个神经元不必感受整幅图像，只需要感受局部就可以了，从猫的视觉神经中发现了局部感受神经元也对该想法的正确性提供了支持(CNN的结构和理论基础启发自神经科学)。</p>
<p><img src="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_8.jpg" alt="aliyun-obser"></p>
<p><img src="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_9.jpg" alt="aliyun-obser"></p>
<p>如果是局部感受野，每个局部感受野<code>10*10</code>,1百万的隐藏神经元有 <code>1000000*(10*10)</code><br>个连接，也就是只有$10^8$ 个参数,但是感觉参数还是很多。后来发现，<font color="red">局部感受野类似于图像的卷积操作，能够提取局部特征，而图像局部的特征检测器也可以用于整个图像，这样就可以提取整幅图像的特征，基于这个特性，我们可以将局部感受野位于不同位置的神经元设置为相同的权值，这些神经元的输出形成CNN中的一个特征图</font>，这样直接将参数个数降到了100个，这就是权值共享的思想。</p>
<p><img src="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_10.jpg" alt="aliyun-obser"></p>
<p>这样只提取了一种特征，为了能够提取多个特征，可以设置多个卷积核，得到多个特征图。</p>
<p>一旦计算出feature map,那么特征精确的位置就变得不重要了,特征的精确位置不仅对识别没有帮助，反而不利于识别，我们只需要知道特征的大概位置就可以了，这与生活中观察到的现象是一致的，两个相似的目标，从远处看，基本看不出区别，但是从近处看，细节方面还是有很多不同的，就很容易识别为两个不同的目标。下采样可以降低特征位置的精度，使得对平移和形变更加鲁棒，实现特征不变性。</p>
<p>上述就是CNN的三大核心思想：</p>
<p><strong>局部感受野(local receptive fields)</strong>:基于图像局部相关的原理，保留了图像局部结构，同时减少了网络的权值</p>
<p><strong>权值共享(shared weights)</strong>: 也是基于图像局部相关的原理，同时减少网络的权值参数</p>
<p><strong>下采样(sub-sampling)</strong>：对平移和形变更加鲁棒，实现特征的不变性，同时起到了一定的降维的作用</p>
<h3 id="连接数和参数个数的计算"><a href="#连接数和参数个数的计算" class="headerlink" title="连接数和参数个数的计算"></a>连接数和参数个数的计算</h3><p>C1层一共122304个连接<br><code>(5*5+1)*28*28*6=122304</code><br>解释：由于每个特征图(feature map)对应一个卷积核和一个偏置，所以特征图中每个像素有26个权值，每个特征图共<code>28*28</code>个像素,一共有6个特征图。</p>
<p>注意：<br>计算连接数量的时候，从每个feature map 的每个像素出发计算。</p>
<h3 id="特征图连接方式"><a href="#特征图连接方式" class="headerlink" title="特征图连接方式"></a>特征图连接方式</h3><p>LeNet中，特征图并不是与前一层所有特征图相连，比如C3层的每个特征图，只与S2层中部分特征图相连，如C3中的第0特征图与S2中的第0,1,2个特征图相连。</p>
<p>而现代CNN中，比如AlexNet,ResNet等, 特征图与前一层的所有特征图相连<br>此时，我们可以将CNN中的核看成是一个三维结构。</p>
<p><img src="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_11.jpg" alt="aliyun-obser"></p>
<p>上图就是AlexNet网络结构示意图，我们可以将卷积核看成是一个三维结构。</p>
<h3 id="各层参数详解"><a href="#各层参数详解" class="headerlink" title="各层参数详解"></a>各层参数详解</h3><p>LeNet-5共<strong>有7层</strong>，不包含输入，每层都包含可训练参数；每个层有<strong>多个Feature Map</strong>，每个FeatureMap通过一种卷积滤波器提取输入的一种特征，然后每个FeatureMap有<strong>多个神经元</strong>。</p>
<ol>
<li><p><strong>C1层是一个卷积层</strong></p>
<p> 输入图片：<code>32*32</code></p>
<p> 卷积核大小：<code>5*5</code></p>
<p> 卷积核种类：6</p>
<p> 输出featuremap大小：<code>28*28</code> （32-5+1）</p>
<p> 神经元数量：<code>28*28*6</code></p>
<p> 可训练参数：<code>（5*5+1）*6</code>（每个滤波器<code>5*5=25</code>个unit参数和一个bias参数，一共6个滤波器）</p>
<p> 连接数：<code>（5*5+1）*6*28*28</code></p>
</li>
<li><p><strong>S2层是一个下采样层</strong></p>
<p> 输入：<code>28*28</code></p>
<p> 采样区域：<code>2*2</code></p>
<p> 采样方式：4个输入相加，乘以一个可训练参数，再加上一个可训练偏置。结果通过sigmoid</p>
<p> 采样种类：6</p>
<p> 输出featureMap大小：<code>14*14</code>（28/2）</p>
<p> 神经元数量：<code>14*14*6</code></p>
<p> 可训练参数：<code>2*6</code>（和的权+偏置）</p>
<p> 连接数：<code>（2*2+1）*6*14*14</code></p>
<p> S2中每个特征图的大小是C1中特征图大小的1/4</p>
</li>
<li><p><strong>C3层也是一个卷积层</strong></p>
<p> 输入：S2中所有6个或者几个特征map组合</p>
<p> 卷积核大小：<code>5*5</code></p>
<p> 卷积核种类：16</p>
<p> 输出featureMap大小：<code>10*10</code></p>
<p> C3中的每个特征map是连接到S2中的所有6个或者几个特征map的，表示本层的特征map是上一层提取到的特征map的不同组合</p>
<p> 存在的一个方式是：C3的前6个特征图以S2中3个相邻的特征图子集为输入。接下来6个特征图以S2中4个相邻特征图子集为输入。然后的3个以不相邻的4个特征图子集为输入。最后一个将S2中所有特征图为输入。</p>
<p> 则：可训练参数：<code>6*（3*25+1）+6*（4*25+1）+3*（4*25+1）+（25*6+1）=1516</code></p>
<p> 连接数：<code>10*10*1516=151600</code></p>
</li>
<li><p><strong>S4层是一个下采样层</strong></p>
<p> 输入：<code>10*10</code></p>
<p> 采样区域：<code>2*2</code></p>
<p> 采样方式：4个输入相加，乘以一个可训练参数，再加上一个可训练偏置。结果通过sigmoid</p>
<p> 采样种类：16</p>
<p> 输出featureMap大小：<code>5*5</code>（10/2）</p>
<p> 神经元数量：<code>5*5*16=400</code></p>
<p> 可训练参数：<code>2*16=32</code>（和的权+偏置）</p>
<p> 连接数：<code>16*（2*2+1）*5*5=2000</code></p>
<p> S4中每个特征图的大小是C3中特征图大小的1/4</p>
</li>
<li><p><strong>C5层是一个卷积层</strong></p>
<p> 输入：S4层的全部16个单元特征map（与s4全相连）</p>
<p> 卷积核大小：<code>5*5</code></p>
<p> 卷积核种类：120</p>
<p> 输出featureMap大小：<code>1*1</code>（5-5+1）</p>
<p> 可训练参数/连接：<code>120*16*（5*5+1）=49920</code></p>
</li>
</ol>
<ol>
<li><p><strong>F6层全连接层</strong></p>
<p> 输入：c5 120维向量</p>
<p> 计算方式：计算输入向量和权重向量之间的点积，再加上一个偏置，结果通过sigmoid函数</p>
<p> 可训练参数:<code>84*(120+1)=10164</code></p>
</li>
</ol>
<p><strong>关于LeNet通俗易懂的讲解，我推荐<a href="http://blog.csdn.net/geekmanong/article/details/50605340" target="_blank" rel="noopener">卷积神经网络Lenet-5实现</a></strong></p>
<p><img src="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/LeNet_12.png" alt="aliyun-obser"></p>
<center><b>Figure15 LeNet-5识别数字3的过程</b></center>

<h2 id="LeNet-5的Tensorflow实现代码"><a href="#LeNet-5的Tensorflow实现代码" class="headerlink" title="LeNet-5的Tensorflow实现代码"></a>LeNet-5的Tensorflow实现代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib.layers <span class="keyword">import</span> flatten</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.utils <span class="keyword">import</span> shuffle</span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data/"</span>, reshape=<span class="keyword">False</span>)</span><br><span class="line">X_train, Y_train = mnist.train.images, mnist.train.labels</span><br><span class="line">X_validation, Y_validation = mnist.validation.images, mnist.validation.labels</span><br><span class="line">X_test, Y_test = mnist.test.images, mnist.test.labels</span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> (len(X_train) == len(Y_train))</span><br><span class="line"><span class="keyword">assert</span> (len(X_validation) == len(Y_validation))</span><br><span class="line"><span class="keyword">assert</span> (len(X_test) == len(Y_test))</span><br><span class="line"></span><br><span class="line">X_train = np.pad(X_train, ((<span class="number">0</span>, <span class="number">0</span>), (<span class="number">2</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">2</span>), (<span class="number">0</span>, <span class="number">0</span>)), <span class="string">'constant'</span>)</span><br><span class="line">X_validation = np.pad(X_validation, ((<span class="number">0</span>, <span class="number">0</span>), (<span class="number">2</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">2</span>), (<span class="number">0</span>, <span class="number">0</span>)), <span class="string">'constant'</span>)</span><br><span class="line">X_test = np.pad(X_test, ((<span class="number">0</span>, <span class="number">0</span>), (<span class="number">2</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">2</span>), (<span class="number">0</span>, <span class="number">0</span>)), <span class="string">'constant'</span>)</span><br><span class="line"></span><br><span class="line">X_train, Y_train = shuffle(X_train, Y_train)</span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">10</span></span><br><span class="line">minibatch_size = <span class="number">128</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line">print_cost = <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_placeholders</span><span class="params">(n_H0, n_W0, n_C0)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Creates the placeholders for the tensorflow session.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    n_H0 -- scalar, height of an input image</span></span><br><span class="line"><span class="string">    n_W0 -- scalar, width of an input image</span></span><br><span class="line"><span class="string">    n_C0 -- scalar, number of channels of the input</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype "float"</span></span><br><span class="line"><span class="string">    Y -- placeholder for the input labels, of shape [None] and dtype "int"</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    X = tf.placeholder(shape=(<span class="keyword">None</span>, n_H0, n_W0, n_C0), dtype=tf.float32)</span><br><span class="line">    Y = tf.placeholder(shape=(<span class="keyword">None</span>), dtype=tf.int32)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X, Y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Initializes weight parameters to build a neural network with tensorflow.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- a dictionary of tensors。</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    mu = <span class="number">0</span></span><br><span class="line">    sigma = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">    conv1_W = tf.Variable(tf.truncated_normal(shape=[<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">6</span>], mean=mu, stddev=sigma))</span><br><span class="line">    conv1_b = tf.Variable(tf.zeros(<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">    conv2_W = tf.Variable(tf.truncated_normal(shape=[<span class="number">5</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">16</span>], mean=mu, stddev=sigma))</span><br><span class="line">    conv2_b = tf.Variable(tf.zeros(<span class="number">16</span>))</span><br><span class="line"></span><br><span class="line">    conv3_W = tf.Variable(tf.truncated_normal(shape=[<span class="number">5</span>, <span class="number">5</span>, <span class="number">16</span>, <span class="number">120</span>], mean=mu, stddev=sigma))</span><br><span class="line">    conv3_b = tf.Variable(tf.zeros(<span class="number">120</span>))</span><br><span class="line"></span><br><span class="line">    fc1_W = tf.Variable(tf.truncated_normal(shape=(<span class="number">120</span>, <span class="number">84</span>), mean=mu, stddev=sigma))</span><br><span class="line">    fc1_b = tf.Variable(tf.zeros(<span class="number">84</span>))</span><br><span class="line"></span><br><span class="line">    fc2_W = tf.Variable(tf.truncated_normal(shape=(<span class="number">84</span>, <span class="number">10</span>), mean=mu, stddev=sigma))</span><br><span class="line">    fc2_b = tf.Variable(tf.zeros(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">    parameters = &#123;</span><br><span class="line">        <span class="string">"conv1_W"</span>: conv1_W,</span><br><span class="line">        <span class="string">"conv1_b"</span>: conv1_b,</span><br><span class="line">        <span class="string">"conv2_W"</span>: conv2_W,</span><br><span class="line">        <span class="string">"conv2_b"</span>: conv2_b,</span><br><span class="line">        <span class="string">"conv3_W"</span>: conv3_W,</span><br><span class="line">        <span class="string">"conv3_b"</span>: conv3_b,</span><br><span class="line">        <span class="string">"fc1_W"</span>: fc1_W,</span><br><span class="line">        <span class="string">"fc1_b"</span>: fc1_b,</span><br><span class="line">        <span class="string">"fc2_W"</span>: fc2_W,</span><br><span class="line">        <span class="string">"fc2_b"</span>: fc2_b</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation</span><span class="params">(X, parameters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements the forward propagation for the model:</span></span><br><span class="line"><span class="string">    CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; FLATTEN -&gt; FULLYCONNECTED -&gt; FULLYCONNECTED</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input dataset placeholder, of shape (number of examples, input size)</span></span><br><span class="line"><span class="string">    parameters -- python dictionary</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    logits -- the output of the last LINEAR unit</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    conv1_W = parameters[<span class="string">"conv1_W"</span>]</span><br><span class="line">    conv1_b = parameters[<span class="string">"conv1_b"</span>]</span><br><span class="line">    conv2_W = parameters[<span class="string">"conv2_W"</span>]</span><br><span class="line">    conv2_b = parameters[<span class="string">"conv2_b"</span>]</span><br><span class="line">    conv3_W = parameters[<span class="string">"conv3_W"</span>]</span><br><span class="line">    conv3_b = parameters[<span class="string">"conv3_b"</span>]</span><br><span class="line">    fc1_W = parameters[<span class="string">"fc1_W"</span>]</span><br><span class="line">    fc1_b = parameters[<span class="string">"fc1_b"</span>]</span><br><span class="line">    fc2_W = parameters[<span class="string">"fc2_W"</span>]</span><br><span class="line">    fc2_b = parameters[<span class="string">"fc2_b"</span>]</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"X: "</span>, X.shape)</span><br><span class="line">    print(<span class="string">"conv1_W: "</span>, conv1_W.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Layer 1: Convolutional. Input = 32x32x1, Output = 28x28x6</span></span><br><span class="line">    conv1 = tf.nn.conv2d(input=X, filter=conv1_W, strides=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'VALID'</span>) + conv1_b</span><br><span class="line">    <span class="comment"># Activation</span></span><br><span class="line">    conv1 = tf.nn.relu(conv1)</span><br><span class="line">    <span class="comment"># Pooling. Input = 28x28x6, Output = 14x14x6</span></span><br><span class="line">    pool_1 = tf.nn.max_pool(value=conv1, ksize=(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>), strides=(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>), padding=<span class="string">'VALID'</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"pool_1: "</span>, pool_1.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Layer 2: Convolutional. Input = 14x14x6, Output = 10x10x16</span></span><br><span class="line">    conv2 = tf.nn.conv2d(input=pool_1, filter=conv2_W, strides=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'VALID'</span>) + conv2_b</span><br><span class="line">    <span class="comment"># Activation</span></span><br><span class="line">    conv2 = tf.nn.relu(conv2)</span><br><span class="line">    <span class="comment"># Pooling. Input = 10x10x16, Output = 5x5x16</span></span><br><span class="line">    pool_2 = tf.nn.max_pool(value=conv2, ksize=(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>), strides=(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>), padding=<span class="string">'VALID'</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"pool_2: "</span>, pool_2.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Layer 3: Convolutional. Input = 5x5x16, Output = 1x1x120</span></span><br><span class="line">    conv3 = tf.nn.conv2d(input=pool_2, filter=conv3_W, strides=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'VALID'</span>) + conv3_b</span><br><span class="line">    <span class="comment"># Activation</span></span><br><span class="line">    conv3 = tf.nn.relu(conv3)</span><br><span class="line">    <span class="comment"># FLATTEN</span></span><br><span class="line">    conv3 = flatten(conv3)</span><br><span class="line">    <span class="comment"># conv3 = tf.nn.dropout(conv3, keep_prob=0.5)</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">"conv3: "</span>, conv3.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Layer 4: Fully Connected. Input = 120, Output = 84</span></span><br><span class="line">    fc1 = tf.matmul(conv3, fc1_W) + fc1_b</span><br><span class="line">    <span class="comment"># Activation</span></span><br><span class="line">    fc1 = tf.nn.relu(fc1)</span><br><span class="line">    fc1 = tf.nn.dropout(fc1, keep_prob=<span class="number">0.5</span>)</span><br><span class="line">    <span class="comment"># Layer 5: Fully Conneceted. Input = 84, Output = 10</span></span><br><span class="line">    logits = tf.matmul(fc1, fc2_W) + fc2_b</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost</span><span class="params">(logits, Y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Computes the cost</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    logits -- output of forward propagation (output of the last LINEAR unit), of shape (number of examples， 10)</span></span><br><span class="line"><span class="string">    Y -- "true" labels vector placeholder, same shape as logits</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    cost - Tensor of the cost function</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    one_hot_Y = tf.one_hot(Y, <span class="number">10</span>)</span><br><span class="line">    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_Y))</span><br><span class="line">    <span class="keyword">return</span> cost</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># tf.reset_default_graph()</span></span><br><span class="line"><span class="comment"># with tf.Session() as sess:</span></span><br><span class="line"><span class="comment">#     X, Y = create_placeholders(32, 32)</span></span><br><span class="line"><span class="comment">#     parameters = initialize_parameters()</span></span><br><span class="line"><span class="comment">#     logits = forward_propagation(X, parameters)</span></span><br><span class="line"><span class="comment">#     cost = compute_cost(logits, Y)</span></span><br><span class="line"><span class="comment">#     init = tf.global_variables_initializer()</span></span><br><span class="line"><span class="comment">#     sess.run(init)</span></span><br><span class="line"><span class="comment">#     a = sess.run(cost, &#123;X: X_train, Y: Y_train&#125;)</span></span><br><span class="line"><span class="comment">#     print("cost=", str(a))</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(X_train, Y_train, X_test, Y_test, learning_rate=learning_rate, num_epochs=num_epochs,</span></span></span><br><span class="line"><span class="function"><span class="params">          minibatch_size=minibatch_size, print_cost=print_cost)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements the LeNet-5 in Tensorflow:</span></span><br><span class="line"><span class="string">    CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; FLATTEN -&gt; FULLYCONNECTED -&gt; FULLYCONNECTED</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X_train -- training set, of shape (None, 32, 32, 1)</span></span><br><span class="line"><span class="string">    Y_train -- test set, of shape (None)</span></span><br><span class="line"><span class="string">    X_test -- training set, of shape (None, 32, 32, 1)</span></span><br><span class="line"><span class="string">    Y_test -- test set, of shape (None)</span></span><br><span class="line"><span class="string">    learning_rate -- learning rate of the optimization</span></span><br><span class="line"><span class="string">    num_epochs -- number of epochs of the optimization loop</span></span><br><span class="line"><span class="string">    minibatch_size -- size of a minibatch</span></span><br><span class="line"><span class="string">    print_cost -- True to print the cost every 100 epochs</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    train_accuracy -- real number, accuracy on the train set (X_train)</span></span><br><span class="line"><span class="string">    test_accuracy -- real number, testing accuracy on the test set (X_test)</span></span><br><span class="line"><span class="string">    parameters -- parameters learnt by the model. They can then be used to predict.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    (m, n_H0, n_W0, n_C0) = X_train.shape</span><br><span class="line">    costs = []</span><br><span class="line">    X, Y = create_placeholders(n_H0, n_W0, n_C0)</span><br><span class="line"></span><br><span class="line">    parameters = initialize_parameters()</span><br><span class="line"></span><br><span class="line">    logits = forward_propagation(X, parameters)</span><br><span class="line"></span><br><span class="line">    cost = compute_cost(logits, Y)</span><br><span class="line"></span><br><span class="line">    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)</span><br><span class="line"></span><br><span class="line">    init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        sess.run(init)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">            X_train, Y_train = shuffle(X_train, Y_train)</span><br><span class="line">            minibatch_cost = <span class="number">0.</span></span><br><span class="line">            num_minibatches = int(m / minibatch_size)</span><br><span class="line">            <span class="keyword">for</span> offset <span class="keyword">in</span> range(<span class="number">0</span>, m, minibatch_size):</span><br><span class="line">                end = offset + minibatch_size</span><br><span class="line">                minibatch_X, minibatch_Y = X_train[offset:end], Y_train[offset:end]</span><br><span class="line">                _, temp_cost = sess.run([optimizer, cost], feed_dict=&#123;X: minibatch_X, Y: minibatch_Y&#125;)</span><br><span class="line">                minibatch_cost += temp_cost / num_minibatches</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> print_cost == <span class="keyword">True</span> <span class="keyword">and</span> epoch % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">                print(<span class="string">"Cost after epoch %i: %f"</span> % (epoch, minibatch_cost))</span><br><span class="line">            <span class="keyword">if</span> print_cost == <span class="keyword">True</span> <span class="keyword">and</span> epoch % <span class="number">1</span> == <span class="number">0</span>:</span><br><span class="line">                costs.append(minibatch_cost)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># plot the cost</span></span><br><span class="line">        plt.plot(np.squeeze(costs))</span><br><span class="line">        plt.ylabel(<span class="string">'cost'</span>)</span><br><span class="line">        plt.xlabel(<span class="string">'iterations (per tens)'</span>)</span><br><span class="line">        plt.title(<span class="string">'Learning rate ='</span> + str(learning_rate))</span><br><span class="line">        <span class="comment"># plt.show()</span></span><br><span class="line">        plt.savefig(<span class="string">'cost.png'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the correct predictions</span></span><br><span class="line">        predict_op = tf.argmax(logits, <span class="number">1</span>)</span><br><span class="line">        correct_prediction = tf.equal(predict_op, tf.argmax(tf.one_hot(Y, <span class="number">10</span>), <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate accuracy on the test set</span></span><br><span class="line">        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">        print(accuracy)</span><br><span class="line">        train_accuracy = accuracy.eval(&#123;X: X_train, Y: Y_train&#125;)</span><br><span class="line">        test_accuracy = accuracy.eval(&#123;X: X_test, Y: Y_test&#125;)</span><br><span class="line">        print(<span class="string">"Train Accuracy:"</span>, train_accuracy)</span><br><span class="line">        print(<span class="string">"Test Accuracy:"</span>, test_accuracy)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> train_accuracy, test_accuracy, parameters</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">_, _, parameters = model(X_train, Y_train, X_test, Y_test)</span><br></pre></td></tr></table></figure>
<table>
    <tr>
        <td>
            <b>Train Accuracy</b>
        </td>
        <td>
            0.99289125
        </td>
    </tr>
    <tr>
        <td>
            <b>Test Accuracy</b>
        </td>
        <td>
            0.9892002
        </td>
    </tr>
</table>

<p><img src="https://obser.oss-cn-beijing.aliyuncs.com/LeNet-5/cost.png" alt="aliyun-obser"></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/python/" rel="tag"><i class="fa fa-tag"></i> python</a>
          
            <a href="/tags/machine-learning/" rel="tag"><i class="fa fa-tag"></i> machine learning</a>
          
            <a href="/tags/tensorflow/" rel="tag"><i class="fa fa-tag"></i> tensorflow</a>
          
            <a href="/tags/经典网络/" rel="tag"><i class="fa fa-tag"></i> 经典网络</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/01/21/Class-4-Week-4-Art-Generation-with-Neural-Style-Transfer/" rel="next" title="deeplearning.ai homework：Class 4 Week 4 Art Generation with Neural Style Transfer">
                <i class="fa fa-chevron-left"></i> deeplearning.ai homework：Class 4 Week 4 Art Generation with Neural Style Transfer
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zMjQ1NS85MDE2"></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
	      <a href="http://obser.cn/about">	
              <img class="site-author-image" itemprop="image"
                src="https://obser.oss-cn-beijing.aliyuncs.com/img/avatar_0.jpg"
                alt="Obser" />
              </a>
            
              <p class="site-author-name" itemprop="name">Obser</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">17</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="qq" target="_blank" title="714893927">
                    
                      <i class="fa fa-fw fa-globe"></i>714893927</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://github.com/obsir" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:Obser47@outlook.com" target="_blank" title="E-Mail">
                    
                      <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="weixin" target="_blank" title="Summer_Obser">
                    
                      <i class="fa fa-fw fa-globe"></i>Summer_Obser</a>
                </span>
              
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#相关资料"><span class="nav-number">1.</span> <span class="nav-text"><a href="#&#x76F8;&#x5173;&#x8D44;&#x6599;" class="headerlink" title="&#x76F8;&#x5173;&#x8D44;&#x6599;"></a>&#x76F8;&#x5173;&#x8D44;&#x6599;</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LeNet论文翻译"><span class="nav-number">2.</span> <span class="nav-text"><a href="#LeNet&#x8BBA;&#x6587;&#x7FFB;&#x8BD1;" class="headerlink" title="LeNet&#x8BBA;&#x6587;&#x7FFB;&#x8BD1;"></a>LeNet&#x8BBA;&#x6587;&#x7FFB;&#x8BD1;</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-用于字符识别的卷积神经网络"><span class="nav-number">2.1.</span> <span class="nav-text"><a href="#2-&#x7528;&#x4E8E;&#x5B57;&#x7B26;&#x8BC6;&#x522B;&#x7684;&#x5377;&#x79EF;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;" class="headerlink" title="2 &#x7528;&#x4E8E;&#x5B57;&#x7B26;&#x8BC6;&#x522B;&#x7684;&#x5377;&#x79EF;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;"></a>2 &#x7528;&#x4E8E;&#x5B57;&#x7B26;&#x8BC6;&#x522B;&#x7684;&#x5377;&#x79EF;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#A-卷积网络"><span class="nav-number">2.2.</span> <span class="nav-text"><a href="#A-&#x5377;&#x79EF;&#x7F51;&#x7EDC;" class="headerlink" title="A &#x5377;&#x79EF;&#x7F51;&#x7EDC;"></a>A &#x5377;&#x79EF;&#x7F51;&#x7EDC;</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#B-LeNet-5"><span class="nav-number">2.3.</span> <span class="nav-text"><a href="#B-LeNet-5" class="headerlink" title="B LeNet-5"></a>B LeNet-5</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LeNet论文解读"><span class="nav-number">2.4.</span> <span class="nav-text"><a href="#LeNet&#x8BBA;&#x6587;&#x89E3;&#x8BFB;" class="headerlink" title="LeNet&#x8BBA;&#x6587;&#x89E3;&#x8BFB;"></a>LeNet&#x8BBA;&#x6587;&#x89E3;&#x8BFB;</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#神经元模型"><span class="nav-number">2.5.</span> <span class="nav-text"><a href="#&#x795E;&#x7ECF;&#x5143;&#x6A21;&#x578B;" class="headerlink" title="&#x795E;&#x7ECF;&#x5143;&#x6A21;&#x578B;"></a>&#x795E;&#x7ECF;&#x5143;&#x6A21;&#x578B;</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#从传统神经网络到CNN"><span class="nav-number">2.6.</span> <span class="nav-text"><a href="#&#x4ECE;&#x4F20;&#x7EDF;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5230;CNN" class="headerlink" title="&#x4ECE;&#x4F20;&#x7EDF;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5230;CNN"></a>&#x4ECE;&#x4F20;&#x7EDF;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5230;CNN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#连接数和参数个数的计算"><span class="nav-number">2.7.</span> <span class="nav-text"><a href="#&#x8FDE;&#x63A5;&#x6570;&#x548C;&#x53C2;&#x6570;&#x4E2A;&#x6570;&#x7684;&#x8BA1;&#x7B97;" class="headerlink" title="&#x8FDE;&#x63A5;&#x6570;&#x548C;&#x53C2;&#x6570;&#x4E2A;&#x6570;&#x7684;&#x8BA1;&#x7B97;"></a>&#x8FDE;&#x63A5;&#x6570;&#x548C;&#x53C2;&#x6570;&#x4E2A;&#x6570;&#x7684;&#x8BA1;&#x7B97;</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特征图连接方式"><span class="nav-number">2.8.</span> <span class="nav-text"><a href="#&#x7279;&#x5F81;&#x56FE;&#x8FDE;&#x63A5;&#x65B9;&#x5F0F;" class="headerlink" title="&#x7279;&#x5F81;&#x56FE;&#x8FDE;&#x63A5;&#x65B9;&#x5F0F;"></a>&#x7279;&#x5F81;&#x56FE;&#x8FDE;&#x63A5;&#x65B9;&#x5F0F;</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#各层参数详解"><span class="nav-number">2.9.</span> <span class="nav-text"><a href="#&#x5404;&#x5C42;&#x53C2;&#x6570;&#x8BE6;&#x89E3;" class="headerlink" title="&#x5404;&#x5C42;&#x53C2;&#x6570;&#x8BE6;&#x89E3;"></a>&#x5404;&#x5C42;&#x53C2;&#x6570;&#x8BE6;&#x89E3;</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LeNet-5的Tensorflow实现代码"><span class="nav-number">3.</span> <span class="nav-text"><a href="#LeNet-5&#x7684;Tensorflow&#x5B9E;&#x73B0;&#x4EE3;&#x7801;" class="headerlink" title="LeNet-5&#x7684;Tensorflow&#x5B9E;&#x73B0;&#x4EE3;&#x7801;"></a>LeNet-5&#x7684;Tensorflow&#x5B9E;&#x73B0;&#x4EE3;&#x7801;</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Obser</span>

  
</div>









        







        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("SbT6UsXvbqheP3nOI2SAUEUF-gzGzoHsz", "tUgsriPeU5TwplN9ISefDhmm");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
